\documentclass[a4paper]{article}
\usepackage{listings}
\usepackage{amsmath}
\newcommand*{\code}[1]{\texttt{#1}}
\usepackage{parskip}
\usepackage{pdfpages}

% \usepackage{pdfpages}
\usepackage{pgffor}
\usepackage{hyperref}      

\hypersetup{
colorlinks = {true}, % color or boxlinks --- keep it true.
linkcolor = {black},
anchorcolor = {black},
citecolor = {black},
menucolor = {black},
filecolor = {black},
urlcolor = {blue},
runcolor = {black},
linkbordercolor = {black},
citebordercolor = {black},
urlbordercolor = {black},
menubordercolor = {black},
filebordercolor = {black},
runbordercolor = {black},
linktoc = {all},
pdfpagelayout = {SinglePage},
pdfstartview = {Fit},
unicode = {true},
}


\begin{document}

\begin{titlepage}
  \title{Documentation of MiniPL Interpreter}
  \author{Siiri Kuoppala}
  \maketitle
  \tableofcontents
\end{titlepage}


\section{Introduction}
This project is an interpreter for a small toy language
called MiniPL. The interpreter was implemented in C++.
It performs all the main phases of interpretation: 
scanning, parsing, semantic analysis (including type checking), 
and execution. The project is built with CMake and tested 
with GoogleTest. GoogleTest is included in the zip file in 
folder \code{libraries}, so it does not need to be installed.

\paragraph*{Dependencies:} Building the project requires CMake, 
which can be installed on Ubuntu with: 
\begin{verbatim}
sudo apt install cmake
\end{verbatim}

\paragraph*{Usage:} Build the project as shown below.

\begin{verbatim}
# create build directory
mkdir build
cd build
cmake ..

# build and run source target
make MiniPL_interpreter_run
bin/MiniPL_interpreter_run <filename>

# build and run test target
make MiniPL_interpreter_tst
bin/MiniPL_interpreter_tst
\end{verbatim}

The \code{samples} directory contains some example programs 
that can be run with the interpreter. Some of them are malformed 
and produce errors to demonstrate the error recovery strategy 
of the interpreter. From the build directory, to run the sample 
\code{samples/1.mpl}, use 
\begin{verbatim}
bin/MiniPL_interpreter_run ../samples/1.mpl
\end{verbatim}

\section{Architecture}


The codebase has the following main components:

\begin{itemize}
  \item \code{MiniPL}: The overall interpreter. Has methods 
        \code{runFile(filename)} and \code{run(program)} for 
        interpreting a given program.
  \item \code{Scanner}:  
        Scans the input program and produces tokens
  \item \code{Parser}:
        Parses the tokens and produces an Abstract Syntax Tree (AST).
  \item \code{SemanticAnalyzer}: Finds semantic
        errors, excluding type errors.
  \item \code{TypeChecker}: Finds type errors.
  \item \code{Interpreter}: Executes the program.
  \item \code{ErrorHandler}: Keeps track of errors. Prints them with
  \code{printErrors()} .
\end{itemize}
The class \code{MiniPL} is the heart of the interpreter. When 
interpreting a program, it initializes 
and runs all the other components in order. It can be constructed 
with references to specific input and output streams as parameters, 
but the default values are standard input and output. 
The \code{main} function in \code{main.cpp} just takes a 
filename as a command line parameter and calls 
\code{MiniPL.runFile(filename)}. 

Most of the data is stored in structs of the following types, 
which only depend on each other:
\begin{itemize}
  \item \code{Position}: A position in the program code (row and column).
  \item \code{Span}: The start and end positions of a token, node or other object.
  \item \code{Token}: One token. Contains a \code{Span} and 
  a \code{TokenValue}.
  \item AST-nodes: Many different types of nodes 
        (see Section \ref{sect:AST}).
  \item Error: Different 
  error types all inherit from \code{ErrorBase}.
\end{itemize}

The main components (other than \code{MiniPL}) do not directly 
communicate with each other, but they all depend on some of 
these structs. 
The \code{Scanner} does not depend on the AST-nodes, and 
the the other components (apart from \code{Parser}) can not 
access tokens. Each component has their own error type that they 
can create. \code{ErrorHandler} can access the error base class 
\code{ErrorBase} but not the specific kinds of errors.


\clearpage
\section{Scanning}

The \code{Scanner} is an ad-hoc scanner with one-character look-ahead.
It has one public method: \code{getToken()}, which scans the next token 
in the program.
It iterates through the program using a small helper-class 
\code{ProgramIterator}, which has methods \code{currentChar()}, 
\code{peekChar()}, and \code{move()} for iterating. The 
iterator additionaly keeps track of the current program \code{Position}, 
which the scanner uses to add a \code{Span} to the tokens.

The scanner always returns a viable token. After reaching the 
end of the program, it just keeps returning an \code{Eof} token 
with the same span. When encountering an error, it skips the 
wrong character and returns the current token or scans the next token, 
depending on where the error happened. For information about 
error messages, see Section \ref{sect:errors}.


\subsection{Token patterns}

There are four five of tokens: identifiers, Keywords, 
literals (integers or strings), operators, and delimiters.
Below is a regular definitions of the possible tokens. 
\begin{itemize}
  \item[] \code{VarIdent} $\rightarrow$ \verb?[A-Za-z][A-Za-z0-9_]*?
  \item[] \code{Literal} $\rightarrow$ \verb_[0-9]+|"([^\n"]|\\(n|t|\n|.))*"_
  \item[] \code{Operator} $\rightarrow$ \verb_+|-|*|/|<|=|\&|!_
  \item[] \code{Delimiter} $\rightarrow$ \verb_:=|;|:|..|(|)|$_
  \item[] \code{TokenValue} $\rightarrow$ \verb_VarIdent|Literal|Operator|Delimiter_
\end{itemize}
The \code{Keyword} tokens form an exception, as they are not scanned 
based on a regular definition. Whenever an identifier is scanned, 
the scanner checks whether it is actually a keyword, and returns 
a \code{Keyword} if necessary.
The possible keywords are  "var", "for", "end", "in", "do", "read", "print", 
"int", "string", "bool", "assert", "if", and "else".

The names above correspond to the type names in the code.  
In the code, identifiers are stored as strings, and literals in a 
struct of type \code{Literal}, containing a value which is 
an integer/string variant, while
values of type \code{Operator}, \code{Delimiter}, and \code{Keyword} 
are stored as enum classes.
The values are stored in the \code{std::variant}
\code{TokenValue}, which may hold any of the above types. 

In addition to the tokens, two types of comments are allowed in 
the language. Single-line comments have the format \verb_//.*_, 
and end at the end of the line. Multi-line comments have the format
\verb_/*...*/_, and can be nested. Nested comments do not allow 
a regular definition, so they form yet another exception. The 
scanner skips all comments and whitespace between tokens.



% \clearpage
\section{Parsing}

The parser is a recursive-descent parser with one-token look-ahead.
It iterates through the tokens with a small helper class 
\code{TokenIterator}, which provides the methods \code{currentToken()} 
and \code{nextToken()} (which moves to the next token and returns that).

\subsection{LL(1) grammar}


\newcommand{\cfgvar}[1]{$<$#1$>$}
\newcommand{\cfgrule}[2]{\text{\cfgvar{#1}} &\rightarrow \text{#2}}
\newcommand{\cfgterm}[1]{\textbf{#1}}
The parser implements the LL(1) grammar shown below.
The terminals are \cfgvar{literal}, \cfgvar{op}, \cfgvar{ident}, 
\cfgvar{unary$\_$op}, the end-of-file symbol \$\$, punctuation 
and the bolded Keywords.

\begin{align*}
  \cfgrule{prog}{\cfgvar{stmts} \$\$} \\
  \cfgrule{stmts}{\cfgvar{stmt}; \cfgvar{stmts} $\mid$ $\varepsilon$} \\
  \cfgrule{stmt}{\cfgvar{decl} $\mid$ 
                 \cfgvar{assign} $\mid$
                 \cfgvar{for} $\mid$ 
                 \cfgvar{read} $\mid$ 
                 \cfgvar{print} $\mid$ 
                 \cfgvar{if} } \\
  \cfgrule{decl}{
    \cfgterm{var} \cfgvar{ident} : \cfgvar{type} \cfgvar{delc\_assign}
  } \\
  \cfgrule{decl\_assign}{
     := \cfgvar{expr} $\mid$ $\varepsilon$
  }\\
  \cfgrule{assign}{
    \cfgvar{ident} := \cfgvar{expr}
  } \\
  \cfgrule{for}{
    \cfgterm{for} \cfgvar{ident} \cfgterm{in} 
    \cfgvar{expr}..\cfgvar{expr} \cfgterm{do} \cfgvar{stmts} 
    \cfgterm{end for}
  } \\
  \cfgrule{read}{
    \cfgterm{read} \cfgvar{ident}
  } \\
  \cfgrule{print}{
    \cfgterm{print} \cfgvar{expr}
  } \\ 
  \cfgrule{if}{
    \cfgterm{if} \cfgvar{expr} \cfgterm{do} \cfgvar{stmts}
    \cfgvar{else} \cfgterm{end if}
  } \\
  \cfgrule{else}{
    \cfgterm{else} \cfgvar{stmts} $\mid$ $\varepsilon$
  } \\
  \cfgrule{expr}{ \cfgvar{expr($0$)} }\\
  \cfgrule{expr($i$)}{ 
    \cfgvar{expr(i+1)} \cfgvar{expr$\_$tail($i$)} 
    $\mid$ \cfgvar{unary$\_$op($i$)} \cfgvar{epxr($i$)}
  } \\
  \cfgrule{expr$\_$tail($i$)}{
    \cfgvar{op($i$)} \cfgvar{expr($i+1$)} \cfgvar{expr$\_$tail($i$)} $\mid$ $\varepsilon$
  } \\
  \cfgrule{expr($\max\_i+1$)}{
    \cfgvar{literal} $\mid$ \cfgvar{ident} 
    $\mid$ \cfgterm{(} \cfgvar{expr} \cfgterm{)}
  } \\
\end{align*}
The grammar is modified from the specification to allow 
for expression with more than two operands. Operator 
precedence is represented with the precedence index $i$ in 
variables \cfgvar{expr($i$)} , \cfgvar{expr$\_$tail($i$)},
\cfgvar{unary$\_$op($i$)} and \cfgvar{op($i$)}. The index goes 
from $0$ (lowest) to max\_i (highest), and the 'operands' 
of expression with level $i$ are expressions of level $i+1$.
There are 6 different precedence classes (copied from C++):
\begin{itemize}
  \item[5:] logical not ($!$)
  \item[4:] div and mul ($/$, $*$)
  \item[3:] add, subtract ($+$, $-$)
  \item[2:] less than ($<$)
  \item[1:] equal ($=$)
  \item[0:] logical and ($\&$)
\end{itemize}

% \subsection{Parser}
The structure of the \code{Parser} differs slightly from this grammar 
because the parsing of the variables \cfgvar{decl} and \cfgvar{decl\_assign}, as well 
as \cfgvar{expr} and \cfgvar{expr\_tail} are merged into single 
methods \code{declaration()} and \code{expression()}.
While parsing, the parser constructs an Abstract Syntax Tree, 
whose structure is descibed in the next section.

\clearpage
\section{Abstract Syntax Trees}
\label{sect:AST}

All AST-nodes inherit the \code{AstNodeBase} class, which contains 
a \code{Span} for error messages. AST-nodes are split into 
statements and expressions, which are mostly handled differently.
They are also stored in different variants.

The type \code{StatementNode} is a 
\code{std::variant} which may contain an AST-node of any of the 
following types:

\begin{itemize}
  \item \code{DeclAstNode}: a declaration.
  \begin{itemize}
    \item[] \code{VarIdent varId}
    \item[] \code{Type type} 
    \item[] \code{optional<ExprAstNode> expr}
  \end{itemize}
  \item \code{AssignAstNode}: assignment
  \begin{itemize}
    \item[] \code{VarIdent varId}
    \item[] \code{ExprAstNode expr}
  \end{itemize}
  \item \code{ForAstNode}: for-statement
  \begin{itemize}
    \item[] \code{VarIdent varId}: loop variable
    \item[] \code{ExprAstNode startExpr, endExpr}: start and end of the range
    \item[] \code{StatementsAstNode stmts}: the statements inside the loop
  \end{itemize}
  \item \code{IfAstNode}: if-statement
  \begin{itemize}
    \item[] \code{ExprAstNode expr}
    \item[] \code{StatementsAstNode ifStatements}
    \item[] \code{StatementsAstNode elseStatements}
  \end{itemize}
  \item \code{ReadAstNode}: read-statement
  \begin{itemize}
    \item[] \code{VarIdent varId}
  \end{itemize}
  \item \code{PrintAstNode}: print-statement
  \begin{itemize}
    \item[] \code{ExprAstNode expr}
  \end{itemize}
  \item \code{StatementsAstNode}: a list of statements
  \begin{itemize}
    \item[] \code{vector<StatementNode> stmts}: list of statements
  \end{itemize}
\end{itemize}

The variant \code{ExprNode} holds nodes of the types:
\begin{itemize}
  \item \code{LiteralNode}: contains a single literal.
  \item \code{VarNode}: contains a variable identifier.
  \item \code{UnaryOp}: contains a unary \code{Operator} and a pointer to an 
  \code{ExprNode}.
  \item \code{BinaryOp}: contains a binary \code{Operator} and 
  pointers to two expressions. 
\end{itemize}

\subsection{Traversal}

The components \code{SemanticAnalyzer}, \code{TypeChecker} and 
\code{Interpreter} all traverse through the AST in the same way. 
They implement \code{visit} functions for all types of AST nodes 
and recursively visit the children.
Instead of using the usual visitor design pattern, they use 
\code{std::visit} to visit the actual objects inside the variants
\code{StatementNode} and \code{ExprAstNode}. This way the 
AST nodes do not need to know anything about the visitors, 
and do not need any methods to accept visitors. 

The traversing 
components do not use inheritance because their \code{visit}-functions 
to expression nodes need different types of return values and 
so can not inherit from the same base class. This is not a large 
problem in the current use case, because each component has 
some special behaviour for most node types. However, using 
inheritance would probably be better because it would make 
implementing changes easier and less likely to cause bugs.
One would just have to circumvent the return-value problem in some way.

\subsection{Semantic analysis and behaviour}

The specification states that MiniPL uses a single global scope 
for all names. This makes it unclear what should happen when 
a variable is declared inside an if- or for-statement, 
especially since variables can only be declared once.
For clarity, I have decided that variables can not be 
declared in inner 'scopes', i.e. inside \code{if} or \code{for}.


The semantic analysis is split into 
two components: \code{SemanticAnalyzer}, and \code{TypeChecker}.
The semantic analyzer checks that all variables are declared 
exactly once, before they are used, that variables are not 
declared inside if- or for-statements, and that 
the loop variable of a for-statement can not be assigned 
inside the loop. The type checker checks that all expressions
and variables have the correct types. If the 
analysis produces no errors, the code can be executed by the 
\code{Interpreter}.

The \code{Interpreter} visits the AST and executes the 
program based on the information in the nodes. The 
variable identifiers are stored in an \code{std::map}.
The read statement is impemented 
using \code{std::cin}, with the failbits on. If an 
incorrect value is given as input, \code{cin} throws an 
exception which is catched by the interpreter and converted 
into a normal MiniPL runtime error.
Integers are stored as the usual 32-bit \code{int}, and 
integer overflow is undefined behaviour (same as C++, no 
additional checks).
In a division operation the interpreter checks that the 
divisor is not zero and causes a runtime error if necessary.


The language specification mentions that print and read 
statements can handle integers and strings, but
I decided to allow boolean values in the print and read 
statements as well. I feel that this is more convenient for 
a programmer who wants to use e.g. debug prints in their 
program.  This also means the there are no type checks 
for read and print. 
In the input and output, Booleans are always printed as 
'0' if false and '1' 
if true. Likewise, when reading a boolean from input, the 
input has to be either '0' or '1'. Inputting any other value 
produces a runtime error.



\section{Error handling}
\label{sect:errors}

All components are given a reference to the \code{ErrorHandler}, 
which they use to raise errors when something unexpected happens.
The \code{ErrorHandler} prints out error messages and keeps track 
of whether errors have been encountered. 
The components then do something component-specific to recover and 
continue processing the input program. If the \code{ErrorHandler} 
has errors after the scanning and parsing passes, the interpreter 
ends the process. Otherwise it continues with semantic analysis 
and, if no errors are encountered, finally runs the program.

\subsection{Error types}

Errors are stored as structs, that all inherit from the 
base struct \code{ErrorBase}. The base struct has members 
\code{context}, \code{contextScope}, and \code{scope}, 
and a public method \code{description()}, which uses 
virtual functions of the derived classes to construct an 
error message. The derived classes and the errors they 
can represent are listed below:
\begin{itemize}
  \item \code{ScanningError}: unexpected character, newline or Eof
  \item \code{ParsingError}: unexpected token
  \item \code{SemanticError}: one of the following
  \begin{itemize}
    \item variable not declared
    \item redeclaration
    \item declaration in inner scope
    \item assignment to a constant variable
  \end{itemize}
  \item \code{TypeError}: wrong type
  \item \code{RuntimeError}: division by zero or IO failure (could not read input)
\end{itemize}

% \subsection{Error messages}

\subsection{Error recovery}

The \code{Scanner} always returns a token when asked, whether or 
not it runs into errors while processing. When a problem is 
encountered and the current token can not be scanned, the scanner 
skips it and scans the next token (after raising an error to the 
handler). In some cases, e.g. when encountering a newline while 
scanning a string, the \code{Scanner} can return the the token it 
was scanning while the error happened. When the end of the 
program has been reached, the Scanner returns an end-of-file token.

The \code{Parser} has an exception-based racovery approach. When the 
\code{match}-function can not match the current token, an error 
is raised and an exception thrown. The exception is caught 
in the \code{statements} function, and tokens are skipped until
the current token is a semicolon or one of the Keywords 
\textbf{var}, \textbf{for}, \textbf{read}, \textbf{print}, 
or \textbf{if}. The parser uses these to find the start of a 
new statements and resumes parsing from that point.


The \code{TypeChecker} can return a \code{Broken} type from e.g.
a malformed expression or an undeclared variable. Type checks 
for broken types are automatically skipped to avoid cascading 
errors. Thus a long expression with a type error in inner 
parenthesis only produces one error. In case of multiple 
declarations of the same variable, the first declaration is 
assumed to be correct.

When \code{Interpreter} produces a runtime error, it 
raises an error to the \code{ErrorHandler} and throws an exception. 
The exception is caught by \code{MiniPL} which asks the 
\code{ErrorHandler} to print the error message and stops running the 
program.

\section{Testing}

Automated testing of the interpreter was implemented with the 
googletest framework. All tests and sample programs were written 
by hand, based on whatever 
things I thought were important. When encountering a bug, I would 
fix the bug and write a test for it. 


The scanner is well tested with unit tests 
covering all different token types, while other components have 
only a few limited unit tests. The whole system is tested with 
integration tests that check whether running the test programs 
produces the expected behaviour. Additionally, there is one 
test that runs all programs in the \code{samples} directory 
and (hopefully) checks that the interpreter doesn't crash.

There are no automatic tests for the error handling and recovery 
functionalities. These were tested by hand, by running the incorrect 
sample programs and looking at the output.
\clearpage
\appendix
  
\newcommand{\pdfappendix}[2]{%
\includepdf[pages={1},scale=0.7, 
pagecommand={\section{#2}\label{pdf:#2}}]{#1}
\includepdf[pages={2-},scale=0.7]{#1}}

% \pdfappendix{MiniPL.pdf}{MiniPL Specification}

% \pdfappendix{CourseProject.pdf}{Project Specification}

\end{document}